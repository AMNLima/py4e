Using Web Services
==================

Once it became easy to retrieve documents and parse documents over HTTP
using programs, it did not take long to develop an approach where we
started producing documents that were specifically designed to be
consumed by other programs (i.e., not HTML to be displayed in a
browser).

There are two common formats that we use when exchanging data across the
web. eXtensible Markup Language (XML) has been in use for a very
long time and is best suited for exchanging document-style data. When
programs just want to exchange dictionaries, lists, or other internal
information with each other, they use JavaScript Object Notation (JSON)
(see [www.json.org](http://www.json.org)). We will look at both formats.

eXtensible Markup Language - XML
--------------------------------

XML looks very similar to HTML, but XML is more structured than HTML.
Here is a sample of an XML document:

~~~~ {.xml}
<person>
  <name>Chuck</name>
  <phone type="intl">
    +1 734 303 4456
  </phone>
  <email hide="yes" />
</person>
~~~~

Each pair of opening (e.g., `<person>`) and closing tags
(e.g., `<\person>`) represents a *element* or *node* with the same
name as the tag (e.g., `person`). Each element can have some text,
some attributes (e.g., `hide`), and other nested elements. If an XML
element is empty (i.e., has no content), then it may be depicted by
a self-closing tag (e.g., `<email />`).

Often it is helpful to think of an XML document as a tree structure
where there is a top element (here: `person`), and other tags (e.g.,
`phone`) are drawn as *children* of their *parent* elements.

![A Tree Representation of XML](height=2.0in@../images/xml-tree)

Parsing XML
-----------

\index{ElementTree}
\index{ElementTree!fromstring}
\index{ElementTree!find}

Here is a simple application that parses some XML and extracts some data
elements from the XML:

\VerbatimInput{../code3/xml1.py} 

The triple single quote (`'''`), as well as the triple double quote (`"""`), allow for the creation of strings that span multiple lines.

Calling `fromstring` converts the string representation of
the XML into a "tree" of XML elements. When the XML is in a tree,
we have a series of methods we can call to extract portions
of data from the XML string.  The `find` function searches
through the XML tree and retrieves the element that matches
the specified tag.

~~~~
Name: Chuck
Attr: yes
~~~~

Using an XML parser such as `ElementTree` has the advantage
that while the XML in this example is quite simple, it turns out there
are many rules regarding valid XML, and using `ElementTree`
allows us to extract data from XML without worrying about the rules of
XML syntax.

Looping through nodes
---------------------

\index{ElementTree!findall}
\index{ElementTree!get}

Often the XML has multiple nodes and we need to write a loop to process
all of the nodes. In the following program, we loop through all of the
`user` nodes:

\VerbatimInput{../code3/xml2.py} 

The `findall` method retrieves a Python list of subtrees that
represent the `user` structures in the XML tree. Then we can
write a `for` loop that looks at each of the user nodes, and
prints the `name` and `id` text elements as well
as the `x` attribute from the `user` node.

~~~~
User count: 2
Name Chuck
Id 001
Attribute 2
Name Brent
Id 009
Attribute 7
~~~~

It is important to include all parent level elements in the `findall`
statement except for the top level element (e.g., `users/user`).
Otherwise, Python will not find any desired nodes.

~~~~ {.python}
import xml.etree.ElementTree as ET

input = '''
<stuff>
  <users>
    <user x="2">
      <id>001</id>
      <name>Chuck</name>
    </user>
    <user x="7">
      <id>009</id>
      <name>Brent</name>
    </user>
  </users>
</stuff>'''

stuff = ET.fromstring(input)

lst = stuff.findall('users/user')
print('User count:', len(lst))

lst2 = stuff.findall('user')
print('User count:', len(lst2))
~~~~

`lst` stores all `user` elements that are nested within their `users`
parent. `lst2` looks for `user` elements that are not nested within
the top level `stuff` element where there are none.

~~~~
User count: 2
User count: 0
~~~~

JavaScript Object Notation - JSON
---------------------------------

\index{JSON}
\index{JavaScript Object Notation}

The JSON format was inspired by the object and array format used in the
JavaScript language. But since Python was invented before JavaScript,
Python's syntax for dictionaries and lists influenced the syntax of
JSON. So the format of JSON is nearly identical to a combination of
Python lists and dictionaries.

Here is a JSON encoding that is roughly equivalent to the simple XML
from above:

~~~~ {.json}
{
  "name" : "Chuck",
  "phone" : {
    "type" : "intl",
    "number" : "+1 734 303 4456"
   },
   "email" : {
     "hide" : "yes"
   }
}
~~~~

You will notice some differences. First, in XML, we can add attributes
like "intl" to the "phone" tag. In JSON, we simply have key-value pairs.
Also the XML "person" tag is gone, replaced by a set of outer curly
braces.

In general, JSON structures are simpler than XML because JSON has fewer
capabilities than XML. But JSON has the advantage that it maps
*directly* to some combination of dictionaries and lists.
And since nearly all programming languages have something equivalent to
Python's dictionaries and lists, JSON is a very natural format to have
two cooperating programs exchange data.

JSON is quickly becoming the format of choice for nearly all data
exchange between applications because of its relative simplicity
compared to XML.

Análise JSON
------------

Construímos nosso JSON por dicionários e listas de aninhamento, conforme necessário. Neste exemplo, representamos uma lista de usuários, onde estes fazem parte de um conjunto de pares de valores-chave (por exemplo, um dicionário). Então nós temos uma lista de dicionários.

No programa a seguir, usamos a biblioteca `json` interna para analisar o JSON e ler os dados. Compare isso de perto com os dados e códigos XML equivalentes acima. O JSON tem menos detalhes, portanto, devemos saber antecipadamente que estamos obtendo uma lista de usuários, e cada usuário é um conjunto de pares de valores-chave. O JSON é mais sucinto (uma vantagem), mas também é menos autodescritivo (uma desvantagem).


\VerbatimInput{../code3/json2.py}

Se você comparar o código para extrair dados do JSON e XML analisados, verá que o que obtemos de `json.loads()` é uma lista do Python que percorremos com um loop `for`, e cada item dentro dessa lista é um dicionário do Python. Uma vez que o JSON tenha sido analisado, podemos usar o operador de indexação do Python para extrair os vários bits de dados para cada usuário. Não precisamos usar a biblioteca JSON para analisar o JSON, pois os dados retornados são simplesmente estruturas nativas do Python.

A saída deste programa é exatamente igual à versão XML acima.

~~~~
User count: 2
Name Chuck
Id 001
Attribute 2
Name Brent
Id 009
Attribute 7
~~~~

Em geral, há uma tendência do setor de XML e de JSON para serviços da web. Como o JSON é mais simples e mapeia mais diretamente estruturas de dados nativas que já temos nas linguagens de programação, o código de análise e extração de dados é geralmente mais simples e mais direto ao usar o JSON. Mas o XML é mais autodescritivo e, portanto, há alguns aplicativos em que o XML mantém uma vantagem. Por exemplo, a maioria dos processadores de texto armazena documentos internamente usando XML em vez de JSON.

Interfaces de Programação de Aplicativos
----------------------------------

Agora temos a capacidade de trocar dados entre aplicativos usando o HyperText Transport Protocol (HTTP) e uma maneira de representar dados complexos que estamos enviando entre esses aplicativos usando XML (Extensible Markup Language) ou JavaScript Object Notation (JSON).

O próximo passo é começar a definir e documentar “contratos” entre aplicativos usando essas técnicas. O nome geral para esses contratos de aplicativo é *Application Program Interfaces* (APIs). Quando usamos uma API, geralmente um programa disponibiliza um conjunto de serviços para uso por outros aplicativos e publica as APIs (ou seja, as "regras") que devem ser seguidas para acessar os serviços fornecidos pelo programa.

Quando começamos a construir nossos programas nos quais a funcionalidade dele inclui o acesso a serviços fornecidos por outros programas, chamamos a abordagem de *Service-Oriented Architecture*  (SOA). Uma abordagem SOA é aquela em que nosso aplicativo geral faz uso dos serviços de outros aplicativos. Uma abordagem não SOA é onde o aplicativo é um aplicativo autônomo único que contém todo o código necessário para implementar o aplicativo.

Nós vemos muitos exemplos de SOA quando usamos a web. Podemos ir a um único site e reservar viagens aéreas, hotéis e automóveis em um único site. Os dados para hotéis não são armazenados nos computadores da companhia aérea. Em vez disso, os computadores da companhia aérea entram em contato com os serviços nos computadores do hotel, recuperam os dados do hotel e os apresentam ao usuário. Quando o usuário concorda em fazer uma reserva de hotel usando o site da companhia aérea, o site da companhia aérea usa outro serviço da web nos sistemas do hotel para realmente fazer a reserva. E quando chega a hora de cobrar seu cartão de crédito por toda a transação, outros computadores ficam envolvidos no processo.

![Service-oriented architecture](height=3.0in@../images/soa)

Uma Service-Oriented Architecture tem muitas vantagens, incluindo: (1) sempre mantemos apenas uma cópia de dados (isso é particularmente importante para coisas como reservas de hotéis em que não queremos ser excessivamente comprometidos) e (2) os proprietários podem definir as regras sobre o uso de seus dados. Com essas vantagens, um sistema SOA deve ser cuidadosamente projetado para ter um bom desempenho e atender às necessidades do usuário.

Quando um aplicativo disponibiliza um conjunto de serviços em sua API pela internet, chamamos de *serviços web*.

Security and API usage
----------------------

\index{OAuth}
\index{API!key}

It is quite common that you need an API key to make use of a
vendor's API. The general idea is that they want to know who is using
their services and how much each user is using. Perhaps they have free
and pay tiers of their services or have a policy that limits the number
of requests that a single individual can make during a particular time
period.

Sometimes once you get your API key, you simply include the key as part
of POST data or perhaps as a parameter on the URL when calling the API.

Other times, the vendor wants increased assurance of the source of the
requests and so they expect you to send cryptographically signed
messages using shared keys and secrets. A very common technology that is
used to sign requests over the Internet is called
*OAuth*. You can read more about the OAuth protocol at
[www.oauth.net](http://www.oauth.net).

Thankfully there are a number of convenient
and free OAuth libraries so you can avoid writing an OAuth
implementation from scratch by reading the specification. These
libraries are of varying complexity and have varying degrees of
richness. The OAuth web site has information about various OAuth
libraries.

Glossary
--------

API
:   Application Program Interface - A contract between applications that
    defines the patterns of interaction between two application
    components.
\index{API}

ElementTree
:   A built-in Python library used to parse XML data.
\index{ElementTree}

JSON
:   JavaScript Object Notation. A format that allows for the markup of
    structured data based on the syntax of JavaScript Objects.
\index{JSON}
\index{JavaScript Object Notation}

SOA
:   Service-Oriented Architecture. When an application is made of
    components connected across a network.
\index{SOA}
\index{Service Oriented Architecture}

XML
:   eXtensible Markup Language. A format that allows for the markup of
    structured data.
\index{XML}
\index{eXtensible Markup Language}

Application 1: Google geocoding web service
----------------------------

\index{Google}
\index{geocoding}
\index{web service}

Google has an excellent web service that allows us to make use of their
large database of geographic information. We can submit a geographical
search string like "Ann Arbor, MI" to their geocoding API and have
Google return its best guess as to where on a map we might find our
search string and tell us about the landmarks nearby.

The geocoding service is free but rate limited so you cannot make
unlimited use of the API in a commercial application. But if you have
some survey data where an end user has entered a location in a
free-format input box, you can use this API to clean up your data quite
nicely.

*When you are using a free API like Google's geocoding API, you
need to be respectful in your use of these resources. If too many people
abuse the service, Google might drop or significantly curtail its free
service.*

\index{rate limiting}

You can read the online documentation for this service, but it is quite
simple and you can even test it using a browser by typing the following
URL into your browser:

[http://maps.googleapis.com/maps/api/geocode/json?address=Ann+Arbor%2C+MI](http://maps.googleapis.com/maps/api/geocode/json?address=Ann+Arbor%2C+MI)

Make sure to unwrap the URL and remove any spaces from the URL before
pasting it into your browser.

The following is a simple application to prompt the user for a search
string, call the Google geocoding API, and extract information from the
returned JSON.

\VerbatimInput{../code3/geojson.py} 

The program takes the search string and constructs a URL with the search
string as a properly encoded parameter and then uses
`urllib` to retrieve the text from the Google geocoding
API. Unlike a fixed web page, the data we get depends on the parameters
we send and the geographical data stored in Google's servers.

Once we retrieve the JSON data, we parse it with the
`json` library and do a few checks to make sure that we
received good data, then extract the information that we are looking
for.

The output of the program is as follows (some of the returned JSON has
been removed):

~~~~
$ python3 geojson.py
Enter location: Ann Arbor, MI
Retrieving http://maps.googleapis.com/maps/api/
  geocode/json?address=Ann+Arbor%2C+MI
Retrieved 1669 characters
~~~~

~~~~ {.json}
{
  "status": "OK",
  "results": [
    {
      "geometry": {
        "location_type": "APPROXIMATE",
        "location": {
          "lat": 42.2808256,
          "lng": -83.7430378
        }
      },
      "address_components": [
        {
          "long_name": "Ann Arbor",
          "types": [
            "locality",
            "political"
          ],
          "short_name": "Ann Arbor"
        }
      ],
      "formatted_address": "Ann Arbor, MI, USA",
      "types": [
        "locality",
        "political"
      ]
    }
  ]
}
lat 42.2808256 lng -83.7430378
Ann Arbor, MI, USA
~~~~

~~~~
Enter location:
~~~~

You can download
[www.py4e.com/code3/geoxml.py](http://www.py4e.com/code3/geoxml.py) to
explore the XML variant of the Google geocoding API.

**Exercise 1: Change either**
[**geojson.py**](http://www.py4e.com/code3/geojson.py) **or**
[**geoxml.py**](http://www.py4e.com/code3/geoxml.py)
**to print out the two-character country code from the retrieved data.
Add error checking so your program does not traceback if the country
code is not there. Once you have it working, search for
"Atlantic Ocean" and make sure it can handle locations
that are not in any country.**

Application 2: Twitter
----------------------

As the Twitter API became increasingly valuable, Twitter went from an
open and public API to an API that required the use of OAuth signatures
on each API request. 

For this next sample program, download the files
*twurl.py*, *hidden.py*, *oauth.py*, and *twitter1.py* from
[www.py4e.com/code](http://www.py4e.com/code3)
and put them all in a folder on your computer.

To make use of these programs you will need to have a Twitter account,
and authorize your Python code as an application, set up a key, secret,
token and token secret. You will edit the file
*hidden.py* and put these four strings into the
appropriate variables in the file:

\VerbatimInput{../code3/hidden.py} 

The Twitter web service are accessed using a URL like this:

<https://api.twitter.com/1.1/statuses/user_timeline.json>

But once all of the security information has been added, the URL will
look more like:

~~~~
https://api.twitter.com/1.1/statuses/user_timeline.json?count=2
&oauth_version=1.0&oauth_token=101...SGI&screen_name=drchuck
&oauth_nonce=09239679&oauth_timestamp=1380395644
&oauth_signature=rLK...BoD&oauth_consumer_key=h7Lu...GNg
&oauth_signature_method=HMAC-SHA1
~~~~

You can read the OAuth specification if you want to know more about the
meaning of the various parameters that are added to meet the security
requirements of OAuth.

For the programs we run with Twitter, we hide all the complexity in the
files *oauth.py* and *twurl.py*. We simply
set the secrets in *hidden.py* and then send the desired
URL to the *twurl.augment()* function and the library
code adds all the necessary parameters to the URL for us.

This program retrieves the timeline for a
particular Twitter user and returns it to us in JSON format in a string.
We simply print the first 250 characters of the string:

\VerbatimInput{../code3/twitter1.py} 
\begin{trinketfiles}
../code3/twurl.py
\end{trinketfiles}

When the program runs it produces the following output:

~~~~
Enter Twitter Account:drchuck
Retrieving https://api.twitter.com/1.1/ ...
[{"created_at":"Sat Sep 28 17:30:25 +0000 2013","
id":384007200990982144,"id_str":"384007200990982144",
"text":"RT @fixpert: See how the Dutch handle traffic
intersections: http:\/\/t.co\/tIiVWtEhj4\n#brilliant",
"source":"web","truncated":false,"in_rep
Remaining 178

Enter Twitter Account:fixpert
Retrieving https://api.twitter.com/1.1/ ...
[{"created_at":"Sat Sep 28 18:03:56 +0000 2013",
"id":384015634108919808,"id_str":"384015634108919808",
"text":"3 months after my freak bocce ball accident,
my wedding ring fits again! :)\n\nhttps:\/\/t.co\/2XmHPx7kgX",
"source":"web","truncated":false,
Remaining 177

Enter Twitter Account:
~~~~

Along with the returned timeline data, Twitter also returns metadata
about the request in the HTTP response headers. One header in
particular, `x-rate-limit-remaining`, informs us how many
more requests we can make before we will be shut off for a short time
period. You can see that our remaining retrievals drop by one each time
we make a request to the API.

In the following example, we retrieve a user's Twitter friends, parse
the returned JSON, and extract some of the information about the
friends. We also dump the JSON after parsing and "pretty-print" it with
an indent of four characters to allow us to pore through the data when
we want to extract more fields.

\VerbatimInput{../code3/twitter2.py} 
\begin{trinketfiles}
../code3/twurl.py
\end{trinketfiles}

Since the JSON becomes a set of nested Python lists and dictionaries, we
can use a combination of the index operation and `for` loops
to wander through the returned data structures with very little Python
code.

The output of the program looks as follows (some of the data items are
shortened to fit on the page):

~~~~
Enter Twitter Account:drchuck
Retrieving https://api.twitter.com/1.1/friends ...
Remaining 14
~~~~

~~~~ {.json}
{
  "next_cursor": 1444171224491980205,
  "users": [
    {
      "id": 662433,
      "followers_count": 28725,
      "status": {
        "text": "@jazzychad I just bought one .__.",
        "created_at": "Fri Sep 20 08:36:34 +0000 2013",
        "retweeted": false,
      },
      "location": "San Francisco, California",
      "screen_name": "leahculver",
      "name": "Leah Culver",
    },
    {
      "id": 40426722,
      "followers_count": 2635,
      "status": {
        "text": "RT @WSJ: Big employers like Google ...",
        "created_at": "Sat Sep 28 19:36:37 +0000 2013",
      },
      "location": "Victoria Canada",
      "screen_name": "_valeriei",
      "name": "Valerie Irvine",
    }
  ],
 "next_cursor_str": "1444171224491980205"
}
~~~~

~~~~
leahculver
   @jazzychad I just bought one .__.
_valeriei
   RT @WSJ: Big employers like Google, AT&amp;T are h
ericbollens
   RT @lukew: sneak peek: my LONG take on the good &a
halherzog
   Learning Objects is 10. We had a cake with the LO,
scweeker
   @DeviceLabDC love it! Now where so I get that "etc

Enter Twitter Account:
~~~~

The last bit of the output is where we see the for loop reading the five
most recent "friends" of the *@drchuck* Twitter account
and printing the most recent status for each friend. There is a great
deal more data available in the returned JSON. If you look in the output
of the program, you can also see that the "find the friends" of a
particular account has a different rate limitation than the number of
timeline queries we are allowed to run per time period.

These secure API keys allow Twitter to have solid confidence that they
know who is using their API and data and at what level. The
rate-limiting approach allows us to do simple, personal data retrievals
but does not allow us to build a product that pulls data from their API
millions of times per day.


